{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liangzhu-Jiang/UTS_ML2019_ID13064593/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MQMcHW2CnID",
        "colab_type": "text"
      },
      "source": [
        "              Assignment 1: Understanding the Literature\n",
        "\n",
        "Title：Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection.\n",
        "\n",
        "                         Introduction\n",
        "                         \n",
        "Among 10 articles, l am interested in face recognition most, so l choose ‘Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection’ as my topic to show what I find and learn from this article. Firstly, this article was written in 1997 by three authors: Peter N. Belhumeur, Joan P. Hespanha and David J. Kriegman. Peter’s research focus lies somewhere in the mix of computer vision, computer graphics, and the visual recognition of plant and animal species. Joan’s current research interests include hybrid and switched systems, multiagent control systems, distributed control over communication networks (also known as networked control systems), the use of vision in feedback control, stochastic modeling in biology, and network security. David’s research is in computer vision with particular application to face recognition, robotics, computer graphics, microscopy, and coral reef ecology. In this article, they will show their research in face recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTQ0Zv8DctY",
        "colab_type": "text"
      },
      "source": [
        "                         Content\n",
        "                         \n",
        "As we all know, face recognition is highly related to lighting direction because different lighting conditions may cause different results. In the past few years, there are many algorithms about face recognition have been proposed. The key issue: small variations in lighting, facial expression and pose has made great progress, however, in some extreme case, the success rate of face recognition is also hard to ensure. Therefore, in this article, authors introduce a new method for face recognition which is insensitive to obvious variations in lighting and facial expressions. However, the lighting variability includes not only intensity but also the direction and number of light sources. Therefore, author also compare four methods for face recognition under variation in lighting and facial expression: Correlation, Eigenfaces method, Linear Subspaces method and Fisherface method which is invented here. Because of Fisherface is a new method so author explains it more detailed than other methods through complex formulas and pictures. Actually, Fisherface technology was invented in 1936 by Fisher which was a technique in pattern recognition at that time. Now, it has been applied in different ways to computer vision and even facial recognition. Then four face recognition techniques will be showed in two particular databases which one is from Harvard Robotics Lab which lighting has been systematically varied and the other is from Yale which includes variation in both facial expression and lighting. Therefore, there will be two experiments, the first one from Harvard test the recognition error rate of four algorithms and compare their recognition error rate, the second one from Yale test how the methods compared under a different range of conditions. What’s more, researchers do a specialized experiment which images from Yale is about “wear glasses” and “not wearing glasses” to compare recognition error rate about Fisherface and PCA (principal components analysis)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHFRJtX6Du0q",
        "colab_type": "text"
      },
      "source": [
        "                        Innovation\n",
        "                        \n",
        "This research takes a pattern classification approach which regard each pixel in an image as a coordinate in a high-dimensional space. Before the start of my theme, l would like to introduce a proper noun which is Lambertian Surface. Firstly, l will define it: A Lambertian surface for reflection is a surface that appears uniformly bright from all directions of view and reflects the entire incident light. Lambertian reflectance is the property exhibited by an ideal matte or diffusely reflecting surface. Then, another proper noun: Linear subspace which is also called vector subspace, it is a vector space that is a subset of some large vector space. Researchers find that the image on a specific face is in a 3D linear subspace of the high dimensional image space in a varying illumination but in a fixed pose, if the face is Lambertian surface without shadows. However, because the face is not a true Lambertian surface and it really bring about a self-shadow so the image will deviate from the linear subspace. Therefore, researchers project the image linearly into the subspace rather than explicitly modelling this bias (traditional method). The projection method is based on Fisher’s linear discriminant which is the innovation of this research. In order to test whether this method is a good and new method, researchers use eigenface technology which is another method but has similar computation requirements to the new method. Therefore, the aim of this experiment is to compare these two methods which error rate is lower. Except fisherface method is an innovative, the whole experiment is also innovative and unprecedented because this experiment wants to test specific assumptions about the relative performance of the algorithm under consideration, therefore, standard databases cannot be used. Researchers specially construct a database in Yale which contains variation in facial expression and lighting. In addition, researchers also use Harvard Robotic Lab which lighting has been systematically varied. Tailored databases mean the innovative of experiment. A general paper only lists the result through words but in this paper, authors not only list algorithms, but also every picture in different situations. I think this is also one of the innovations which can help readers to understand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA5L9UGRD3yT",
        "colab_type": "text"
      },
      "source": [
        "                        Technical quality\n",
        "\n",
        "Actually, when l first read this paper, l felt very confused about this content Therefore, l searched for some information about those methods. After l read some basic knowledge, l found this work in the paper has high technical quality. There are four methods in the paper, authors briefly introduce Correlation method and Linear method which include the usage situation and limitation and authors mainly focus on the Eigenfaces and Fisherfaces. Next l will describe the whole experiment. All the experiments were done among four methods. First, researchers do the variation in light experiment (Harvard Database). The current situation is: 1) On each image in this database a subject held his\\her head steady while being illuminated by a dominant light source. 2)  5 subsets consisting of images of 5 people with varying light were used for this experiment. 3) Recognition was performed using nearest neighbor classifier. Then each method was trained on samples from subset 1 and tested using samples from subsets 1,2,3. Then researchers do this experiment again which each method was trained on subsets 1 & 5 and then tested on subsets 2,3,4. The result is: Eigenface’s error rate is the highest in two experiments while Fisherface’s error rate is the lowest in two experiments. In order to ensure the accuracy of the conclusion, researchers do another experiment: variation in facial expression, eyewear and lighting experiment. (Yale Database) The current situation is: 1) The Database contains 160 frontal face images covering 16 individuals taken under 10 different conditions: A normal image under ambient lighting, one with or without glasses, 3 images taken with different point light sources, and 5 different facial expressions 2) Recognition was performed using nearest neighbor classifier. The result is: no matter close crop or full face, Eigenface has the highest error rate while the Fisherface has the lowest error rate among the four methods. Therefore, the conclusion is obvious which Fisherface method is the best methods to do recognition now. Researchers do these two rigorous experiments which conclusion is convincing. Through the whole experiments, we can see this work has high technical quality. All experiments have pictures and related result which readers can easily know the conclusion and how researchers do the experiment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3melBXjD_1b",
        "colab_type": "text"
      },
      "source": [
        "                    Application and X-factor\n",
        "                    \n",
        "Obviously, l think the application domain is appropriate for the proposed technique. Face recognition is an important and commonly used technology in nearly all the field. Therefore, in this article, the author proposes this new method which has the lowest error rate which is a meaningful progress for current face recognition technology. In our daily life this technology is everywhere: 1) Face recognition is an important tool for police to catch the crime suspect. 2) Most places can use facial recognition as an access control. 3) Face recognition can also be used in various kinds of occasion to monitor sites. Certainly, except our daily life, face recognition is also used in research field like AI, Intelligent research on robots and so on. Actually, this experiment is really good but l think some of the factors cannot be ignored. Therefore, l would like to propose some suggestions. This experiment can eliminate the effects of light to the greatest extent possible however, the face changes with age. With the increase of age, the appearance of wrinkles and the relaxation of facial muscles will change the structure and texture of the face. Researchers can focus on this point because this is a realistic problem. At present, researchers have solved the lighting problem, but age problem is always a tough problem. Face recognition is a popular topic, in my opinion, the work described in the paper can spark a good discussion in class. Students can propose their opinions about this work even give some suggestions or improvement. This work based on the real people’s face so explore the result of which method can has the highest accuracy is an exciting event. I think the process of exploration is the most interesting thing which attracts me.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSBKA6gJEF4T",
        "colab_type": "text"
      },
      "source": [
        "                         Presentation\n",
        "                         \n",
        "This paper contains words, pictures and tables which has a clear presentation. It is easy to find the argument of this paper is to introduce Fisherface method and whether this method can do well in accuracy rate. Certainly, this paper uses two experiments show the Fisherface method is well-deserved best methods among four methods. The whole presentation style likes teacher introduces new knowledge to students. As a reader, it is easy to follow authors’ point because the depth of the argument is not very deep if you read some related knowledge in advance. In conclusion, this paper is suitable for some face recognition lovers and learners even they cannot completely understand the whole content. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT9jccRyELqM",
        "colab_type": "text"
      },
      "source": [
        "                         Reference\n",
        "                         \n",
        "1.\tZhao, W., Chellappa, R., Phillips, P.J. & Rosenfeld, A. 2003, ‘Face recognition: A literature survey’, ACM Computing Surveys (CSUR), vol. 35, no. 4, pp. 399-458.\n",
        "\n",
        "2.\tJonathon Phillips, P., Jiang, F., Narvekar, A., Ayyad, J. & O’Toole, Alice J. 2011, ‘An other-race effect for face recognition algorithms’, ACM Transactions on Applied Perception (TAP), vol. 8, no. 2, article no. 14. \n",
        "\n",
        "3.\tLiu, C. 2014, ‘The development trend of evaluating face-recognition technology’, 2014 International Conference on Mechatronics and Control (ICMC), 3-5 July, Jinzhou, China, pp. 1540-1544.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STe1nZjSFctn",
        "colab_type": "text"
      },
      "source": [
        "                           Link\n",
        "https://colab.research.google.com/github/Liangzhu Jiang/UTS_ML2019_ID13064593/blob/master/A1.ipynb"
      ]
    }
  ]
}